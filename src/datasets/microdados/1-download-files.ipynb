{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping dos arquivos de Microdados\n",
    "\n",
    "este notebook realiza o download de todos os arquivos de microdados disponíveis (no site do IBGE)[https://www.ibge.gov.br/estatisticas/sociais/trabalho/22827-censo-demografico-2022.html?edicao=37225&t=microdados]. Os microdados estão separados por censo (2000 e 2010) e por UF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import requests\n",
    "import zipfile\n",
    "sys.path.append('../..')\n",
    "\n",
    "# Data Manipulation\n",
    "import pandas as pd\n",
    "\n",
    "# from utils import *\n",
    "\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.ibge.gov.br/estatisticas/sociais/trabalho/22827-censo-demografico-2022.html?edicao=37225&t=microdados\"\n",
    "\n",
    "DATA_PATH = \"../../data/\"\n",
    "\n",
    "# The following variables determine which cells will be run, default is true for all variables\n",
    "config_vars = {\n",
    "    'download_zips': True # Download zips from IBGE website\n",
    "    ,'unzip_files': True # Unzip the .zip files\n",
    "    move_up_files\n",
    "    ,'rename_files': True # Rename files according to the definition {research}_{year}_{UF}.txt\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1- Download dos Arquivos .zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 7.33 s\n",
      "Wall time: 2min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if config_vars['download_zips'] == True:\n",
    "    census_list = []\n",
    "    \n",
    "    # scrape the html from IBGE's website\n",
    "    soup = bs(requests.get(url).text)\n",
    "\n",
    "    # find all unordered lists and iterate over them\n",
    "    uls = soup.find_all(\"ul\")\n",
    "    for ul in uls:\n",
    "    # find all links in the unordered list and iterate over them\n",
    "        ul_as = ul.find_all(\"a\")\n",
    "        for ul_a in ul_as:\n",
    "            # if one of the links refers to the state name \"Acre\", the list contains the census data\n",
    "            if ul_a.text == \"Acre\":\n",
    "                census_list.append(ul)\n",
    "\n",
    "    # iterate over the census data list\n",
    "    for census in census_list:\n",
    "        # find all links in the census data list and iterate over them\n",
    "        census_as = census.find_all(\"a\")\n",
    "        for census_a in census_as:\n",
    "            # get the text of the link\n",
    "            href = census_a['href']\n",
    "            # get the year from the link's text\n",
    "            idx_year = int(href.index(\"Censo_Demografico_\") + len(\"Censo_Demografico_\"))\n",
    "            nm_year = href[idx_year:int(idx_year) + 4]\n",
    "            # get the uf from the link's text\n",
    "            nm_uf = href[href.rindex(\"/\") + 1:-4]\n",
    "            # define the filename\n",
    "            nm_file = f\"{DATA_PATH}/{nm_year}_{nm_uf}.zip\"\n",
    "            # download the file\n",
    "            urllib.request.urlretrieve(href, nm_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2- Unzip dos arquivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 39.6 s\n",
      "Wall time: 2min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if config_vars['unzip_files'] == True:\n",
    "    for file_path in os.listdir(DATA_PATH):\n",
    "        if file_path.endswith('.zip'):\n",
    "            with zipfile.ZipFile(DATA_PATH + file_path, 'r') as zip_ref:\n",
    "                try:\n",
    "                    zip_ref.extractall(DATA_PATH)\n",
    "                    zip_ref.close()\n",
    "                    os.remove(DATA_PATH + file_path)\n",
    "                except Exception as e:\n",
    "                    # print(f'File: {file_path} not processed due to Error: \\n{e}')\n",
    "                    pass\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3- Renomeia os arquivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config_vars['move_up_files'] == True:\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
