{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping dos arquivos de Microdados\n",
    "\n",
    "este notebook realiza o download de todos os arquivos de microdados disponíveis (no site do IBGE)[https://www.ibge.gov.br/estatisticas/sociais/trabalho/22827-censo-demografico-2022.html?edicao=37225&t=microdados]. Os microdados estão separados por censo (2000 e 2010) e por UF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import shutil\n",
    "import requests\n",
    "import zipfile\n",
    "sys.path.append('../..')\n",
    "\n",
    "# Data Manipulation\n",
    "import pandas as pd\n",
    "\n",
    "# from utils import *\n",
    "\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.ibge.gov.br/estatisticas/sociais/trabalho/22827-censo-demografico-2022.html?edicao=37225&t=microdados\"\n",
    "\n",
    "DATA_PATH = \"../../data/\"\n",
    "\n",
    "# The following variables determine which cells will be run, default is true for all variables\n",
    "config_vars = {\n",
    "    'download_zips': True # Download zips from IBGE website\n",
    "    ,'unzip_files': True # Unzip the .zip files\n",
    "    ,'delete_zips': False # Delete zips after unzip\n",
    "    ,'move_up_files': True # Move files from subfolders to the root folder\n",
    "    ,'rename_files': True # Rename files according to the definition {research}_{year}_{UF}.txt\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1- Download dos Arquivos .zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 15.5 s\n",
      "Wall time: 2min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if config_vars['download_zips'] == True:\n",
    "    census_list = []\n",
    "    \n",
    "    # scrape the html from IBGE's website\n",
    "    soup = bs(requests.get(url).text)\n",
    "\n",
    "    # find all unordered lists and iterate over them\n",
    "    uls = soup.find_all(\"ul\")\n",
    "    for ul in uls:\n",
    "    # find all links in the unordered list and iterate over them\n",
    "        ul_as = ul.find_all(\"a\")\n",
    "        for ul_a in ul_as:\n",
    "            # if one of the links refers to the state name \"Acre\", the list contains the census data\n",
    "            if ul_a.text == \"Acre\":\n",
    "                census_list.append(ul)\n",
    "\n",
    "    # iterate over the census data list\n",
    "    for census in census_list:\n",
    "        # find all links in the census data list and iterate over them\n",
    "        census_as = census.find_all(\"a\")\n",
    "        for census_a in census_as:\n",
    "            # get the text of the link\n",
    "            href = census_a['href']\n",
    "            # get the year from the link's text\n",
    "            idx_year = int(href.index(\"Censo_Demografico_\") + len(\"Censo_Demografico_\"))\n",
    "            nm_year = href[idx_year:int(idx_year) + 4]\n",
    "            # get the uf from the link's text\n",
    "            nm_uf = href[href.rindex(\"/\") + 1:-4]\n",
    "            # define the filename\n",
    "            nm_file = f\"{DATA_PATH}/{nm_year}_{nm_uf}.zip\"\n",
    "            # download the file\n",
    "            urllib.request.urlretrieve(href, nm_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2- Unzip dos arquivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 44.8 s\n",
      "Wall time: 2min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if config_vars['unzip_files'] == True:\n",
    "    for file_path in os.listdir(DATA_PATH):\n",
    "        if file_path.endswith('.zip'):\n",
    "            with zipfile.ZipFile(DATA_PATH + file_path, 'r') as zip_ref:\n",
    "                try:\n",
    "                    zip_ref.extractall(DATA_PATH)\n",
    "                    zip_ref.close()                    \n",
    "                except Exception as e:\n",
    "                    # print(f'File: {file_path} not processed due to Error: \\n{e}')\n",
    "                    pass\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config_vars['delete_zip_files'] == True:\n",
    "    for file_path in os.listdir(DATA_PATH):\n",
    "        if file_path.endswith('.zip'):\n",
    "            os.remove(DATA_PATH + file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3- Renomeia os arquivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_file_name = {\n",
    "    # 2010 files\n",
    "    'Amostra_Domicilios_': 'amostra_domicilios_2010_',\n",
    "    'Amostra_Emigracao_': 'amostra_emigracao_2010_',\n",
    "    'Amostra_Mortalidade_': 'amostra_mortalidade_2010_',\n",
    "    'Amostra_Pessoas_': 'amostra_pessoas_2010_',\n",
    "    # 2000 files\n",
    "    'DOM': 'amostra_domicilios_2000_',\n",
    "    'FAM': 'amostra_familias_2000_',\n",
    "    'PES': 'amostra_pessoas_2000_',\n",
    "}\n",
    "\n",
    "def rename_file(file_name, UF):\n",
    "    for old, new in new_file_name.items():\n",
    "        if old.upper() in file_name.upper():\n",
    "            return new + UF + '.txt'\n",
    "    return file_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WinError 183] Não é possível criar um arquivo já existente: '../../data/RN/DOM25.txt' -> '../../data/microdados/amostra_domicilios_2000_RN.txt'\n",
      "[WinError 183] Não é possível criar um arquivo já existente: '../../data/RN/FAMI25.TXT' -> '../../data/microdados/amostra_familias_2000_RN.txt'\n",
      "[WinError 183] Não é possível criar um arquivo já existente: '../../data/RN/PES25.txt' -> '../../data/microdados/amostra_pessoas_2000_RN.txt'\n"
     ]
    }
   ],
   "source": [
    "if config_vars['move_up_files'] == True:\n",
    "    for dir in os.listdir(DATA_PATH):\n",
    "        dir_path = os.path.join(DATA_PATH, dir)\n",
    "        if os.path.isdir(dir_path) and dir != 'microdados' and dir != 'outros':\n",
    "            for file in os.listdir(dir_path):\n",
    "                file_path = dir_path + '/' + file\n",
    "                try:\n",
    "                    if file.lower().endswith('.txt'):\n",
    "                        new_file_path = DATA_PATH + 'microdados/' + rename_file(file, dir)\n",
    "                    else:\n",
    "                        new_file_path = DATA_PATH + 'outros/' + file\n",
    "                    os.rename(file_path, new_file_path)\n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "            shutil.rmtree(dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
